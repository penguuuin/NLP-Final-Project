{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3499,
     "status": "ok",
     "timestamp": 1566970390531,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "O5PyrlI04-nf",
    "outputId": "9cb1c831-6593-4c24-ee8b-37e26153ddcd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "# print( tf.VERSION )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8H7mVpQ4-oZ"
   },
   "outputs": [],
   "source": [
    "data_path = 'q3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YT3xecgZu9cy"
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(2000, len(lines) - 1)]:\n",
    "    input_text = line.split('\\t')[0]\n",
    "    target_text = line.split('\\t')[1]\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1566970783839,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "t3BTZCofvDDM",
    "outputId": "f302c475-db73-42c8-e579-e940e7bafc3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_gZi8kAujGz"
   },
   "outputs": [],
   "source": [
    "zippedList =  list(zip(input_texts, target_texts))\n",
    "lines = pd.DataFrame(zippedList, columns = ['input' , 'output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1566970843462,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "zaot_rwEvXBc",
    "outputId": "7017b6b7-138b-43c9-d633-3fafb7605e78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The kitchen stinks .</td>\n",
       "      <td>I'll throw out the garbage .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Getting worse . Now he ’ s eating me out of h...</td>\n",
       "      <td>Leo , I really think you ’ re beating around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leo , I really think you ’ re beating around ...</td>\n",
       "      <td>You ’ re right . Everything is probably going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm not sure . But I'll get a table ready as ...</td>\n",
       "      <td>OK . We'll wait .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thanks a lot . That's the favor I was going t...</td>\n",
       "      <td>The pleasure is mine .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0                              The kitchen stinks .    \n",
       "1   Getting worse . Now he ’ s eating me out of h...   \n",
       "2   Leo , I really think you ’ re beating around ...   \n",
       "3   I'm not sure . But I'll get a table ready as ...   \n",
       "4   Thanks a lot . That's the favor I was going t...   \n",
       "\n",
       "                                              output  \n",
       "0                      I'll throw out the garbage .   \n",
       "1   Leo , I really think you ’ re beating around ...  \n",
       "2   You ’ re right . Everything is probably going...  \n",
       "3                                 OK . We'll wait .   \n",
       "4                            The pleasure is mine .   "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1566970853149,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "iB-LfSHe4-ol",
    "outputId": "26d97950-1610-404f-aa34-8ade21ed43e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input max length is 148\n",
      "Encoder input data shape -> (2000, 148)\n",
      "Number of Input tokens = 2935\n"
     ]
    }
   ],
   "source": [
    "input_lines = list()\n",
    "for line in lines.input:\n",
    "    input_lines.append( line ) \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( input_lines ) \n",
    "tokenized_input_lines = tokenizer.texts_to_sequences( input_lines ) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_input_lines:\n",
    "    length_list.append( len( token_seq ))\n",
    "max_input_length = np.array( length_list ).max()\n",
    "print( 'Input max length is {}'.format( max_input_length ))\n",
    "\n",
    "padded_input_lines = preprocessing.sequence.pad_sequences( tokenized_input_lines , maxlen=max_input_length , padding='post' )\n",
    "encoder_input_data = np.array( padded_input_lines )\n",
    "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
    "\n",
    "input_word_dict = tokenizer.word_index\n",
    "num_input_tokens = len( input_word_dict )+1\n",
    "print( 'Number of Input tokens = {}'.format( num_input_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1566970862207,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "49gbwsHS4-oy",
    "outputId": "143e9654-370c-4fda-b438-38d60402573d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output max length is 150\n",
      "Decoder input data shape -> (2000, 150)\n",
      "Number of Output tokens = 2561\n"
     ]
    }
   ],
   "source": [
    "output_lines = list()\n",
    "for line in lines.output:\n",
    "    output_lines.append( '<START> ' + line + ' <END>' )  \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( output_lines ) \n",
    "tokenized_output_lines = tokenizer.texts_to_sequences( output_lines ) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_output_lines:\n",
    "    length_list.append( len( token_seq ))\n",
    "max_output_length = np.array( length_list ).max()\n",
    "print( 'Output max length is {}'.format( max_output_length ))\n",
    "\n",
    "padded_output_lines = preprocessing.sequence.pad_sequences( tokenized_output_lines , maxlen=max_output_length, padding='post' )\n",
    "decoder_input_data = np.array( padded_output_lines )\n",
    "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
    "\n",
    "output_word_dict = tokenizer.word_index\n",
    "num_output_tokens = len( output_word_dict )+1\n",
    "print( 'Number of Output tokens = {}'.format( num_output_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing target data for the Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1566970870299,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "VXAhyQxL4-o8",
    "outputId": "e796634e-a73f-4f9b-d206-85678aac2d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder target data shape -> (2000, 150, 2561)\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data = list()\n",
    "for token_seq in tokenized_output_lines:\n",
    "    decoder_target_data.append( token_seq[ 1 : ] ) \n",
    "    \n",
    "padded_output_lines = preprocessing.sequence.pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "onehot_output_lines = utils.to_categorical( padded_output_lines , num_output_tokens )\n",
    "decoder_target_data = np.array( onehot_output_lines )\n",
    "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2329,
     "status": "ok",
     "timestamp": 1566970890357,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "LkRUlgU-4-pS",
    "outputId": "4e34b83d-4f0b-4ad2-9209-746f8e698c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 256)    751360      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 256)    655616      input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 256), (None, 525312      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   [(None, None, 256),  525312      embedding_7[0][0]                \n",
      "                                                                 lstm_6[0][1]                     \n",
      "                                                                 lstm_6[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 2561)   658177      lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,115,777\n",
      "Trainable params: 3,115,777\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( num_input_tokens, 256 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True , recurrent_dropout=0.2 , dropout=0.2 )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( num_output_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( num_output_tokens , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118763,
     "status": "ok",
     "timestamp": 1566972590170,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "S5mbCw1Q4-pd",
    "outputId": "790ac443-17cb-4376-e9e5-35d020dd583d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples\n",
      "Epoch 1/250\n",
      "2000/2000 [==============================] - 13s 6ms/sample - loss: 0.6038\n",
      "Epoch 2/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.4655\n",
      "Epoch 3/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.4395\n",
      "Epoch 4/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.4301\n",
      "Epoch 5/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.4202\n",
      "Epoch 6/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.4100\n",
      "Epoch 7/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.4030\n",
      "Epoch 8/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3972\n",
      "Epoch 9/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3924\n",
      "Epoch 10/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3882\n",
      "Epoch 11/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3835\n",
      "Epoch 12/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3793\n",
      "Epoch 13/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3748\n",
      "Epoch 14/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3704\n",
      "Epoch 15/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3654\n",
      "Epoch 16/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3603\n",
      "Epoch 17/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3556\n",
      "Epoch 18/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3514\n",
      "Epoch 19/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3471\n",
      "Epoch 20/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3434\n",
      "Epoch 21/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3396\n",
      "Epoch 22/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3362\n",
      "Epoch 23/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3328\n",
      "Epoch 24/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3293\n",
      "Epoch 25/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3262\n",
      "Epoch 26/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3229\n",
      "Epoch 27/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3199\n",
      "Epoch 28/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3167\n",
      "Epoch 29/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3138\n",
      "Epoch 30/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3108\n",
      "Epoch 31/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3079\n",
      "Epoch 32/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3049\n",
      "Epoch 33/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.3020\n",
      "Epoch 34/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2992\n",
      "Epoch 35/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2962\n",
      "Epoch 36/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2935\n",
      "Epoch 37/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2909\n",
      "Epoch 38/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2884\n",
      "Epoch 39/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2856\n",
      "Epoch 40/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2833\n",
      "Epoch 41/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2806\n",
      "Epoch 42/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2783\n",
      "Epoch 43/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2758\n",
      "Epoch 44/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2731\n",
      "Epoch 45/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2707\n",
      "Epoch 46/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2684\n",
      "Epoch 47/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2662\n",
      "Epoch 48/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2640\n",
      "Epoch 49/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2612\n",
      "Epoch 50/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2589\n",
      "Epoch 51/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2564\n",
      "Epoch 52/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2542\n",
      "Epoch 53/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2519\n",
      "Epoch 54/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2499\n",
      "Epoch 55/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2474\n",
      "Epoch 56/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2452\n",
      "Epoch 57/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2426\n",
      "Epoch 58/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2403\n",
      "Epoch 59/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2382\n",
      "Epoch 60/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2357\n",
      "Epoch 61/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2336\n",
      "Epoch 62/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2315\n",
      "Epoch 63/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2287\n",
      "Epoch 64/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2267\n",
      "Epoch 65/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2242\n",
      "Epoch 66/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2221\n",
      "Epoch 67/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2197\n",
      "Epoch 68/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2174\n",
      "Epoch 69/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2149\n",
      "Epoch 70/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2125\n",
      "Epoch 71/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2107\n",
      "Epoch 72/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2083\n",
      "Epoch 73/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2057\n",
      "Epoch 74/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2033\n",
      "Epoch 75/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.2010\n",
      "Epoch 76/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1991\n",
      "Epoch 77/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1965\n",
      "Epoch 78/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1942\n",
      "Epoch 79/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1922\n",
      "Epoch 80/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1898\n",
      "Epoch 81/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1873\n",
      "Epoch 82/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1850\n",
      "Epoch 83/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1826\n",
      "Epoch 84/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1804\n",
      "Epoch 85/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1782\n",
      "Epoch 86/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1759\n",
      "Epoch 87/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1737\n",
      "Epoch 88/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1714\n",
      "Epoch 89/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1688\n",
      "Epoch 90/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1671\n",
      "Epoch 91/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1648\n",
      "Epoch 92/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1625\n",
      "Epoch 93/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1606\n",
      "Epoch 94/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1581\n",
      "Epoch 95/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1562\n",
      "Epoch 96/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1537\n",
      "Epoch 97/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1522\n",
      "Epoch 98/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1500\n",
      "Epoch 99/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1482\n",
      "Epoch 100/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1461\n",
      "Epoch 101/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1441\n",
      "Epoch 102/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1420\n",
      "Epoch 103/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1402\n",
      "Epoch 104/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1378\n",
      "Epoch 105/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1364\n",
      "Epoch 106/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1344\n",
      "Epoch 107/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1324\n",
      "Epoch 108/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1306\n",
      "Epoch 109/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1294\n",
      "Epoch 110/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1271\n",
      "Epoch 111/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1251\n",
      "Epoch 112/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1237\n",
      "Epoch 113/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1222\n",
      "Epoch 114/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1203\n",
      "Epoch 115/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1187\n",
      "Epoch 116/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1171\n",
      "Epoch 117/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1155\n",
      "Epoch 118/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1137\n",
      "Epoch 119/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1120\n",
      "Epoch 120/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1108\n",
      "Epoch 121/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1093\n",
      "Epoch 122/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1076\n",
      "Epoch 123/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1059\n",
      "Epoch 124/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1042\n",
      "Epoch 125/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1029\n",
      "Epoch 126/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1017\n",
      "Epoch 127/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.1001\n",
      "Epoch 128/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0988\n",
      "Epoch 129/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0971\n",
      "Epoch 130/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0960\n",
      "Epoch 131/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0948\n",
      "Epoch 132/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0932\n",
      "Epoch 133/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0918\n",
      "Epoch 134/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0904\n",
      "Epoch 135/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0894\n",
      "Epoch 136/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0879\n",
      "Epoch 137/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0867\n",
      "Epoch 138/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0854\n",
      "Epoch 139/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0843\n",
      "Epoch 140/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0831\n",
      "Epoch 141/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0821\n",
      "Epoch 142/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0809\n",
      "Epoch 143/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0797\n",
      "Epoch 144/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0785\n",
      "Epoch 145/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0775\n",
      "Epoch 146/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0763\n",
      "Epoch 147/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0754\n",
      "Epoch 148/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0740\n",
      "Epoch 149/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0733\n",
      "Epoch 150/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0723\n",
      "Epoch 151/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0709\n",
      "Epoch 152/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0702\n",
      "Epoch 153/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0690\n",
      "Epoch 154/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0685\n",
      "Epoch 155/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0671\n",
      "Epoch 156/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0663\n",
      "Epoch 157/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0654\n",
      "Epoch 158/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0645\n",
      "Epoch 159/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0635\n",
      "Epoch 160/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0627\n",
      "Epoch 161/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0619\n",
      "Epoch 162/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0609\n",
      "Epoch 163/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0600\n",
      "Epoch 164/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0597\n",
      "Epoch 165/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0586\n",
      "Epoch 166/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0578\n",
      "Epoch 167/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0569\n",
      "Epoch 168/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0560\n",
      "Epoch 169/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0554\n",
      "Epoch 170/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0544\n",
      "Epoch 171/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0537\n",
      "Epoch 172/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0529\n",
      "Epoch 173/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0522\n",
      "Epoch 174/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0514\n",
      "Epoch 175/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0506\n",
      "Epoch 176/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0501\n",
      "Epoch 177/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0494\n",
      "Epoch 178/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0487\n",
      "Epoch 179/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0481\n",
      "Epoch 180/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0474\n",
      "Epoch 181/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0467\n",
      "Epoch 182/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0457\n",
      "Epoch 183/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0452\n",
      "Epoch 184/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0448\n",
      "Epoch 185/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0440\n",
      "Epoch 186/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0436\n",
      "Epoch 187/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0428\n",
      "Epoch 188/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0425\n",
      "Epoch 189/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0416\n",
      "Epoch 190/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0409\n",
      "Epoch 191/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0407\n",
      "Epoch 192/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0400\n",
      "Epoch 193/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0397\n",
      "Epoch 194/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0388\n",
      "Epoch 195/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0385\n",
      "Epoch 196/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0381\n",
      "Epoch 197/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0374\n",
      "Epoch 198/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0370\n",
      "Epoch 199/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0361\n",
      "Epoch 200/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0358\n",
      "Epoch 201/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0355\n",
      "Epoch 202/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0351\n",
      "Epoch 203/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0344\n",
      "Epoch 204/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0341\n",
      "Epoch 205/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0337\n",
      "Epoch 206/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0329\n",
      "Epoch 207/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0325\n",
      "Epoch 208/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0322\n",
      "Epoch 209/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0317\n",
      "Epoch 210/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0316\n",
      "Epoch 211/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0309\n",
      "Epoch 212/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0307\n",
      "Epoch 213/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0301\n",
      "Epoch 214/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0297\n",
      "Epoch 215/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0295\n",
      "Epoch 216/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0287\n",
      "Epoch 217/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0285\n",
      "Epoch 218/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0279\n",
      "Epoch 219/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0276\n",
      "Epoch 220/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0277\n",
      "Epoch 221/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0272\n",
      "Epoch 222/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0267\n",
      "Epoch 223/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0263\n",
      "Epoch 224/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0259\n",
      "Epoch 225/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0255\n",
      "Epoch 226/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0254\n",
      "Epoch 227/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0250\n",
      "Epoch 228/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0245\n",
      "Epoch 229/250\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0242\n",
      "Epoch 230/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0239\n",
      "Epoch 231/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0239\n",
      "Epoch 232/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0233\n",
      "Epoch 233/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0231\n",
      "Epoch 234/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0226\n",
      "Epoch 235/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0225\n",
      "Epoch 236/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0223\n",
      "Epoch 237/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0220\n",
      "Epoch 238/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0218\n",
      "Epoch 239/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0213\n",
      "Epoch 240/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0211\n",
      "Epoch 241/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0208\n",
      "Epoch 242/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0203\n",
      "Epoch 243/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0201\n",
      "Epoch 244/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0200\n",
      "Epoch 245/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0198\n",
      "Epoch 246/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0195\n",
      "Epoch 247/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0192\n",
      "Epoch 248/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0189\n",
      "Epoch 249/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0187\n",
      "Epoch 250/250\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0182\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=124, epochs=250) \n",
    "model.save( 'model_q3.h5' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe8wYN0Z4-pt"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=(256,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=(256,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRZQUhXb4-p6"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( input_word_dict[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56399,
     "status": "error",
     "timestamp": 1566972712128,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "dtO9QVI67N65",
    "outputId": "be16a472-04bf-438e-f04a-d9ef9f07062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n",
      "Bot: even him that is your change\n",
      "\n",
      "User: what do you mean\n",
      "Bot: thank you i hope so\n",
      "\n",
      "User: hello\n",
      "Bot: hello i'd like to have a vacant apartment\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-8ccfc47a46c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mstates_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'User: '\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mempty_target_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_word_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m             \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "enc_model.save( 'enc_model_q3.h5' ) \n",
    "dec_model.save( 'dec_model_q3.h5' ) \n",
    "\n",
    "\n",
    "for epoch in range( encoder_input_data.shape[0] ):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'User: ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = output_word_dict['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in output_word_dict.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( \"Bot:\" +decoded_translation.replace(' end', '') )\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
